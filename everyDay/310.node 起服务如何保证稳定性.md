# Problem: node 起服务如何保证稳定性?

*[interview]: start
## node 服务的稳定性
对于稳定性，可以分为开发、测试、代码部署、正式上线、回归测试、hotfix处理阶段

## 开发过程
开发时代码质量保证

规范新建目录的路径及名称、方便团队项目管理
使用 eslint 代码检测
每个函数体的大小行数规范管理
git 分支以及 git 提交记录和 git changelog.md 管理

## 测试阶段
主要是分为 sql 接口测试和接口压力测试

sql 接口测试，这里通过 sql 的测试用例，从业务原型抽取测试逻辑，设置边界值，重复循环的测试，当然这里也是测试对应的 sql 表是否达到上线标准

接口压测测试验收，主要测的是 TPS、QPS 和系统吞吐量，简单来说就是将测试服务压力提升到 100%，找到瓶颈处，对于不同环境的接口的吞吐量，接口压力降级等，只要使用的 jmeter 测试工具进行；设置好线程数，线程启动时间，压测时间(可以设置超长时间的测试)，

QPS

Queries Per Second 意思是"每秒查询率"，是一台服务器每秒能够相应的查询次数，是一个特定的查询服务器在规定时间内所处理流量多少的衡量标准

TPS
TransanctionPerSecond 意思是"事务数/秒"。它是软件测试结果的测量单位。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束及时，以此来计算使用的时间和完成的事务个数。

TPS 即每秒处理事务数，包括： 用户请求服务器 服务器自己的内部处理 服务器返回给用户

这三个过程，每秒能够完成 N 个这三个过程，TPS 也就是 N

QPS 基本类似于 TPS，但是不相同的是：对于一个页面的一次访问，形成一个 TPS;但一次页面请求，可能产生多次对服务器的请求，服务器对这些请求就可计入"QPS"之中。例如：访问一个页面会请求服务器 3 次，一次放，产生一个"TPS",产生 3 个"QPS"


系统吞吐量
一个系统的吞吐量(承压能力)与 request 对 CPU 的消耗，外部接口、IO 等等紧密关联。单个 request 对 CPU 消耗越高、外部系统接口、IO 影响速度越慢，系统吞吐能力越低，反之越高

系统吞吐量的几个重要参数：

QPS(TPS):每秒钟 request/事务 数量
并发数：系统同时处理的 request/事务数
响应时间：一般取平均响应时间
可以推算出它们之间的关系：QPS(TPS)=并发数/平均响应时间 或者 并发数=QPS*平均响应时间

当我们吞吐不理想时，这时需要降低一个请求的响应时间，就算是毫秒级的处理也会给服务器性能带来十分大的影响

## 部署阶段
网络方面网络均衡方面选用 nginx 对我们的服务进行反向代理以及负载均衡

部署方式：分布式部署不同节点的服务器

部署容器：使用 docker+k8s 搭建 node 服务运行环境，在大吞吐量下可做到伸缩扩容

多 node 服务器下，使用中心指挥官，对 node 服务快速部署启动进行管理，可选用 zookeeper 和携程的 Apollo 进行 node 集群管理

## 正式上线
上线准备主要是日志服务的运行稳定，因为很多报错信息以及服务复盘资料的来源，完善的日志服务和日志打点是完善一个服务很好的工具

## hotfix
hotfix：是系统出现了问题，需要紧急处理的一个方案；下面就是对于 master 处理的流程，如果经过了 5 次修复依然存在 bug，则将出现问题的模块剔除出来，作为下一次迭代任务的前置任务，用在下一次上线

在服务监控方面 错误日志的监控 心跳监控 监控预警系统 。。。

上面只是简单的叙述了 node 服务稳定运行的一部分基础措施，还有很多工作需要根据时间情况再去做方案

>使用pm2做多进程及进程守护来保证其稳定性

## 关键词: 开发、测试、代码部署、正式上线、回归测试、hotfix处理阶段、pm2
*[interview]: end
